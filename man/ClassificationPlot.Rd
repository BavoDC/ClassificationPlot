% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ClassificationPlot.R
\name{ClassificationPlot}
\alias{ClassificationPlot}
\title{Classification plot}
\usage{
ClassificationPlot(model1, model2, outcome, data, cutoffs = seq(0, 0.9, by =
  0.1), pointwiseCI = c("none", "TPR", "FPR", "both"),
  pointwiseCIcutoff = NULL, col1 = "darkgreen", col2 = "red", lwd = 3,
  TreatAll = T, colTreatAll = "grey", TreatNone = T,
  colTreatNone = "black", SNBpl = T, colSNB = "blue", axes = T,
  ShowAUC = T, AUCcoord = c(0.625, 0.95), LegCoord = c(0.75, 1.05),
  y.intersp = 0.75, RiskSet = c("model1", "model2", "both", "none"),
  cex.leg = 0.75, cex.auc = 0.85, GraphSettings = NULL,
  PrintMessages = T, UtilityMeasures = c("default", "accuracy", "utility"),
  loc = -0.2, LabelsModels = c("Model 1", "Model 2"), ylab = "Proportion",
  ...)
}
\arguments{
\item{model1}{Variable with the risks of the (baseline) model.}

\item{model2}{Variable with the risks of the competing model.}

\item{outcome}{Response variable.}

\item{data}{Dataframe in which the predicted risks are to be found}

\item{cutoffs}{A vector containing the cutoffs for which the performance measures need to be calculated.}

\item{pointwiseCI}{Can be used to plot the pointwise confidence intervals of the TPR and/or FPR at specific cutoffs.
\code{"TPR"} when this needs to be plotted for the TPR, \code{"FPR"} when this only needs to be plotted for the FPR
and \code{"both"} when it has to be plotted for both the FPR and TPR.}

\item{pointwiseCIcutoff}{A vector of cutoffs for which the pointwise confidence intervals have to be calculated.}

\item{col1}{Color for the lines of the TPR model(s).}

\item{col2}{Color for the lines of the FPR of the model(s).}

\item{lwd}{Linewidth of the lines in the plot.}

\item{TreatAll}{Logical, indicates if treat all has to be shown on the plot. Default is \code{TRUE}.}

\item{colTreatAll}{Color of treat all.}

\item{TreatNone}{Logical, indicates if treat none has to be shown on the plot. Default is \code{TRUE}.}

\item{colTreatNone}{Color of treat none.}

\item{SNBpl}{Logical, indicates if SNB has to be shown on the plot. Default is \code{TRUE}.}

\item{colSNB}{Color of SNB.}

\item{axes}{Axes command of \code{\link{plot}}, default is \code{TRUE}. If set to \code{FALSE}, only the y- and x-axis
will be shown on the plot.}

\item{ShowAUC}{Logical, indicates if the AUC has to be shown on the plot. Default is \code{TRUE}.}

\item{AUCcoord}{Vector of length two with the coordinates of the AUCs on the plot. \code{\link{locator}} can also be used.}

\item{LegCoord}{Vector of length two with the coordinates of the legend on the plot. \code{\link{locator}} can also
be used.}

\item{y.intersp}{Character interspecing factor for vertical distance.}

\item{RiskSet}{Indicates if performance measures have to be shown (see UtilityMeasures for further specification) below
the plot. Specify \code{'model1'} for the performance measures of model 1, \code{'model2'}
for those of model 2 and \code{'both'} if the performance measures for both models have to be shown..
\code{'none'} suppresses the printing. Default is \code{'model1'}.}

\item{cex.leg}{Size of the legend.}

\item{cex.auc}{Size of the AUCs shown on the plot.}

\item{GraphSettings}{List with graphical settings. See \code{\link{par}}.}

\item{PrintMessages}{Logical, indicates whether messages have to be printed while the function is calculating the
performance measures and preparing the plot. Default is \code{TRUE}.}

\item{UtilityMeasures}{Indicates which performance measures have to be shown for each of the cutoffs. Specify
\code{'default'} for the true and false positive rate (TPR and FPR, respectively) and
\code{'accuracy'} to additionally show the positive likelihood ratio (PLR), negative likelihood ratio (NLR),
 positive predictive value (PPV) and negative predictive value (NPV).
\code{'Utility'} shows the TPR, FPR, standardized net benefit (SNB), net TP per 100 and NNT for 1 TP if the
predicted risks of one model are given. In case of 2 models, the TPR and FPR for both models are given
as well as the difference in SNB and the difference in net TP per 100. Only possible for the default cutoffs.
Default is \code{'proportions'}.}

\item{loc}{Specifies the x-coordinates for the titles of the RiskSet.}

\item{LabelsModels}{The labels for the model(s) when \code{Riskset!='none'}.}

\item{ylab}{Label for the y-axis.}

\item{...}{Arguments to be passed to \code{\link{plot}}, see \code{\link{par}}.}
}
\value{
The classification plot is plotted and an object containing the performance measures of the model(s) is returned.
}
\description{
This function can be used to visualize the performance measures and create a custom classification plot of a model or two competing models.
An object is also returned containing the performance measures of the model(s).
}
\examples{
#---------#
# 1 model #
#---------#

# simulated data
X      = replicate(4, rnorm(5e2))
p0true = binomial()$linkinv(cbind(1, X)\%*\%c(0.1, 0.5, 1.2, -0.75, 0.8))
y      = rbinom(5e2, 1, p0true)
Df     = data.frame(y,X)

# fit logistic model
FitLog = glm(y~., Df, family=binomial)
Pred   = binomial()$linkinv(cbind(1, X)\%*\%coef(FitLog))
Df2    = cbind.data.frame(Pred = Pred, Outcome = y)

# Classification plot
ClassificationPlot(Pred, outcome = Outcome, data=Df2)

#----------#
# 2 models #
#----------#

# Fit second model
FitLog2 = glm(y~., Df[,1:3], family=binomial)
Pred2   = binomial()$linkinv(cbind(1, X[,1:2])\%*\%coef(FitLog2))
Df3    = cbind.data.frame(Model1 = Pred, Model2 = Pred2, Outcome = y)

# Classification plot
ClassificationPlot(Model1, Model2, Outcome, Df3)
ClassificationPlot(Model1, Model2, Outcome, Df3, RiskSet = "both")
ClassificationPlot(Model1, Model2, Outcome, Df3, RiskSet = "both", UtilityMeasures = "utility")
}
\references{
Verbakel JY, Steyerberg EW, Uno H, De Cock B, Collins G, Van Calster B. From ROC curves to classification plots for markers 
and models: from wast of ink towards useful insights. \emph{Submitted}.

Vickers AJ, Elkin EB. Decision Curve Analysis: A Novel Method for Evaluating Prediction Models.
\emph{Medical Decision Making} 2006, 26(6): 565-574

Van Calster B, Vickers A, Pencina M, Baker S, Timmerman D, Steyerberg EW.
Evaluation of Markers and Risk Prediction Models: Overview of Relationships between NRI and Decision-Analytic
 easures. \emph{Medical Decision Making} 2013, 33(4): 490-501.

Vickers AJ, Van Calster B, Steyerberg EW. Net benefit approaches to the evaluation
of prediction models, molecular markers and diagnostic tests. \emph{British Medical Journal} 2016, 352
}
